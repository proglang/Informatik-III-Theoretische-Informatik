\section[Komplexitätstheorie]{Komplexitätstheorie}
\subsection{Komplexitätsklassen und \ac{P}/\ac{NP}}

{\color{red} TODO: Dieser rote Teil des Skripts wir erst im Lauf des Wochenendes in einen akzeptablen Zustand gebracht.

Aus Info2 kennen Sie: Worst-case Laufzeit eines Algorithmus bestimmen.

Hier: Betrachte Problemstellung und bestime was Wort-case Laufzeit von bestmöglichem Algorithmus ist.

}


\begin{Def}
Sei $f:\N\rightarrow\N$ eine Funktion und $\M$ eine \ac{NTM} mit Eingabealphabet $\Sigma$.
\begin{itemize}
 \item $\M$ hat \emph{Zeitkomplexität} $f(n)$, falls $\forall w\in\Sigma^*$ mit Länge $n$ gilt: $\M$ hält auf Eingabe $w$ für jede Berechnung in höchstens $f(n)$ Schritten.
 \item $\M$ hat \emph{Platzkomplexität} $f(n)$, falls $\forall w\in\Sigma^*$ mit Länge $n$ gilt: Wenn $\M$ auf $w$ angesetzt wird, benutzt jede Berechnung höchstens $f(n)$ Bandzellen.
 \qedhere
\end{itemize}
\end{Def}


\begin{Def}[name={[$\NTIME$ Klasse]}]
	Sei $f:\N\->\N$ eine Funktion.
	\begin{align*}
	\DTIME(f(n)) = \{L \subseteq\Sigma^*\mid & \text{ Es gibt det. Mehrband-\ac{TM} $\M$, sodass $L(\M)=L$ und }\\
	                & \text{$\M$ hat Zeitkomplexität $f(n)$} \}\\
%     \end{align*}
%     \begin{align*}
    \NTIME(f(n)) = \{L \subseteq\Sigma^*\mid & \text{ Es gibt nichtdet. Mehrband-\ac{TM} $\M$, sodass $L(\M)=L$ und }\\
                    & \text{$\M$ hat Zeitkomplexität $f(n)$} \}\\           
%     \end{align*}
% 	\begin{align*}
	\DSPACE(f(n)) = \{L \subseteq\Sigma^*\mid & \text{ Es gibt det. Mehrband-\ac{TM} $\M$, sodass $L(\M)=L$ und }\\
	                & \text{$\M$ hat Platzkomplexität $f(n)$} \}\\
%     \end{align*}
%     \begin{align*}
    \NSPACE(f(n)) = \{L \subseteq\Sigma^*\mid & \text{ Es gibt nichtdet. Mehrband-\ac{TM} $\M$, sodass $L(\M)=L$ und }\\
                    & \text{$\M$ hat Platzkomplexität $f(n)$} \}\qedhere
    \end{align*}	

% 	Die Klasse $\NTIME(f(n))$ besteht aus allen Sprachen, die von einer (Mehrkanal-)\ac{TM} $M$ in $T_M(w)\leq f(|w|)$ akzeptiert werden.\\
% 	Dabei $T_M(w) =
% 	\begin{cases}
% 		\mathrlap{\text{Anzahl der Schritte einer kürzesten akzeptierenden Berechnung von $M$ auf }w}\\
% 		1 & \text{falls }\nexists
% 	\end{cases}$\\
\end{Def}

{\color{red}

Diagramm: Raute mit Inklusionen

Erklärung dazu.

% \bigskip
% 
% Probleme als Sprachen.
% 
% Bsp: Erfüllbarkeitsproblem der Aussagenlogik.
% 
% \begin{Def}[name={[\ac{SAT}: Erfüllbarkeitsproblem der \acs*{AL}]}]
% 	\ac{SAT}, das Erfüllbarkeitsproblem der \acf{AL} ist  definiert durch
% 	\begin{description}
% 	\item[Eingaben:] Formal $F$ der \acl{AL}.
% 	\item[Frage:] Ist $F$ erfüllbar, d.h. existiert eine Belegung $\beta$ der Variablen mit $\{0,1\}$, sodass $F[\beta]=1$ ist.
% 	\end{description}
% 	$\ac{SAT}=\{\code(F) \mid F\text{ist erfüllbare Formel der \acs{AL}}\}$
% \end{Def}

}

Wir wollen im Folgenden Probleme als Sprachen darstellen und beginnen zunächst mit dem Erfüllbarkeitsproblem der Aussagenlogik.

\goodbreak

\textbf{Aussagenlogische Formeln als Sprachen}

Wir gehen davon aus, dass die Leser des Skripts mit \ac{AL}\footnote{%
Eine Einführung in Aussagenlogik finden Sie im Skript zur Vorlesung \emph{Logik für Studierende der Informatik} aus dem WS 2017/18.
Wir werden in dieser Vorlesung eine sehr ähnliche Notation verwenden.
\url{http://home.mathematik.uni-freiburg.de/junker/ws17/logik-info.html}
}
vertraut sind, stellen die von uns verwendete Syntax vor und bitten den Leser, sich die entsprechende Semantik zu erschließen.

Im Folgenden möchten wir Mengen von \ac{AL}-Formeln als Sprachen beschreiben.
Dafür müssen wir zunächst ein geeignetes Alphabet wählen.
Dabei nehmen wir ``0'' und ``1'' für die Konstanten,
``$\neg$'', ``$\land$'' und ``$\lor$ für die Junktoren
und runde Klammern ''$($`` und ''$)$``.
Bei der Darstellung der Aussagenvariablen stehen wir nun vor der folgenden Herausforderung:
Es gibt unendliche viele Aussagenvariablen $A_0,A_1,A_2,A_3,\ldots$, aber unser Alphabet kann nur endlich viele Zeichen haben.
Unsere Lösung dafür ist sehr ähnlich wie die, die wir auch auf Papier verwenden.
Wir stellen eine Aussagenvariable durch ein ''$A$`` dar, das von einer Ziffernfolge gefolgt wird.
Die Aussagenvariable $A_{1337}$ wir so durch das Wort $A1337$ der Länge 5 repräsentiert.
Wir müssen unser Alphabet also noch um ''$A$``, ''$2$``, $\ldots$ ''$9$`` ergänzen und erhalten
$$\Sigma_\mathsf{AL}=\{0,1,2,3,4,5,6,7,8,9,A,\neg,\land,\lor,(,)\}.$$

\begin{Def}\label{def:gal}
Die Menge der \ac{AL}-Formeln ist die Sprache der kontextfreien Grammatik
  $\mathcal{G}_\mathsf{AL} = (\Sigma_\mathsf{AL}, N, P, S)$ mit
	\begin{align*}
		N &= \{S,Z\}\\
		P &= \begin{aligned}[t]
      \{ S \to\ & 0\mid 1\mid AZ\mid \neg S\mid (S\land S)\mid (S\lor S)\\
        Z \to\ & 0Z\mid 1Z\mid 2Z\mid 3Z\mid 4Z\mid 5Z\mid 6Z\mid 7Z\mid 8Z\mid 9Z \mid \\
        &0 \mid 1 \mid 2 \mid 3 \mid 4 \mid 5 \mid 6 \mid 7 \mid 8 \mid 9\}.
        \end{aligned}
      \qedherefixaligned
	\end{align*}
\end{Def}

Wir nehmen nun unsere Definition von Formeln, um ein bekanntes Problem mit Hilfe einer Sprache zu beschreiben.
\begin{Def}
Wir nennen die Menge der erfüllbaren \ac{AL}-Formeln \acsu{SAT}.
\[ \ac{SAT}=\{F\mid F\in L(\mathcal{G}_\mathsf{AL}) \text{ und $F$ erfüllbar}\}\qedhere \]
\end{Def}


Wir haben nun also die Frage, ob die Formel $F$ erfüllbar ist, als Wortproblem ''$F\in \ac{SAT}?$`` dargestellt.
Wir wollen im Folgenden eine \ac{TM} konstruieren, die \ac{SAT} entscheidet, betrachten aber als Vorstufe hierfür zunächst eine einfachere Sprache.


Wir definieren uns $\mathcal{G}_\mathsf{AL0}$ als die obige Grammatik, in der die Regel $S\to AZ$ fehlt.
Offensichtlich enthält $L(\mathcal{G}_\mathsf{AL0})$ genau die \ac{AL}-Formeln, die keine Aussagenvariablen enthalten.

Weiter definieren wir 
$$\text{SAT}_0=\{F\mid F\in L(\mathcal{G}_\mathsf{AL0}) \text{ und $F$ erfüllbar}\}$$
und konstruieren eine \ac{DTM}, die $\text{SAT}_0$ entscheidet.

\begin{Bsp}\label{bsp:DtmSat0}
Sei $\M_{SAT_0}$ eine DTM deren Verhalten wir wie folgt informell beschreiben.
\begin{itemize}
 \item Grundlegende Idee: Laufe von links nach rechts über die Eingabe und ersetze alle Operationen auf Konstantensymbolen direkt durch das Ergebnis (z.B. $1\land 0\rightsquigarrow 0$).
 Wiederhole bis $0$ oder $1$ auf dem Band steht.
 \item Problem: Resultat hat weniger Zeichen als Operation.
 \item Lösung: Erweitere Bandalphabet um ein Zeichen $\blacksquare$ um enstandene Leerstellen zu markieren (z.B. $1\land 0\rightsquigarrow 0\blacksquare\blacksquare$). Alternative: Verschiebe Bandinhalt ensprechend.
\end{itemize}
\end{Bsp}

Frage: Was ist die bestmögliche Laufzeitkomplexität, die wir für $\M_{SAT_0}$ geben können?

Antwort: Wir müssen im schlimmsten Fall für jede Operator ein mal über die Eingabe laufen. 
Die Laufzeitkomplexität ist also ''garantiert nicht viel schlimmer als $n^2$`` wobei $n$ die Größe der Eingabe ist.
Wir könen die Laufzeitkomplexität aber nicht exakt angeben, da die Beschreibung von $\M_{SAT_0}$ zu unpräzise ist.
(Läuft der Kopf gelegentlich links und rechts über die Eingabe hinaus um das Wortende zu bestimmen?
Läuft der Kopf beim Ersetzen zurück?)

Ein Formalismus um Aussagen wie ''garantiert nicht viel schlimmer als...``
zu beschreiben ist das (groß) $\mathcal{O}$ Symbol der Bachmann–Landau Notation.
Wir vermuten dass die Leser des Skriptes mit diesem Formalismus vertraut sind, wollen die Definition von (groß) $\mathcal{O}$ hier nochmal wiederholen.

\begin{Def} Sei $g:\N\rightarrow\N$
\[ \mathcal{O}(g(n)) = \{f:\N\rightarrow\N \mid \exists n_0, k\in\N:\, \forall n\geq n_0: f(n)\leq k\cdot g(n)\} \qedhere \]
\end{Def}
Die Klasse $\mathcal{O}(g(n))$ enthält also genau die Funktionen die für große Argumente durch ein vielfaches von $g(n)$ beschränkt sind.

Über die Schwierigkeit von $SAT_0$ können wir nun also sagen:
Es gibt ein $f(n)\in\mathcal{O}(n^2)$ sodass $SAT_0\in\DTIME(f(n))$.

\begin{Bsp}\label{bsp:NtmSat}
Sei $\M_{SAT}$ eine NTM deren Verhalten wir wie folgt informell beschreiben.
\begin{itemize}
 \item Phase 1: Laufe über die Eingabe, sammle alle Aussagenvariablen $A_{k_1},\ldots,A_{k_n}$, rate (wähle nichtderministisch) für jede davon eine Belegung $b_{k_i}$ und schreibe 
 $$A_{k_1}=b_{k_1},\quad\ldots,\quad A_{k_n}=b_{k_n}$$
 auf ein zweites Band.
 Dabei soll jede Variable höchstens ein mal geschrieben werden, auch wenn sie mehrfach in der Eingabe vorkommt.
  
 Zeitkomplexität: 
 Ein Vergleich zweier Aussagenvariablen ist in $\mathcal{O}(n)$ möglich,
 pro Variablen müssen höchstens $\mathcal{O}(n)$ Vergleiche gemacht werden und
 in der Eingabe sind höchtens $\mathcal{O}(n)$ Variablen enthalten.
 Die Zeitkomplexität von Phase 1 kann also durch durch $\mathcal{O}(n)^3$ beschränkt werden.
 
 \item Phase 2: Laufe über die Eingabe und ersetze alle Aussagenvariablen durch die geratene Belegung.
 
 Zeitkomplexität: Durch $\mathcal{O}(n)^3$ beschränkt, nahezu gleiche Argumentation wie oben.
 
 \item Phase 3: Wende die in \autoref{bsp:NtmSat} beschriebene DTM $\M_{SAT_0}$ auf den Bandinhalt an.
 
 Zeitkomplexität: Durch $\mathcal{O}(n)^2$ beschränkt.
\end{itemize}
Die Zeitkomplexität von $\M_{SAT}$ ist also durch $\mathcal{O}(n)^3$ beschränkt.
\end{Bsp}

Über die Schwierigkeit von $SAT$ können wir somit sagen:
Es gibt ein $f(n)\in\mathcal{O}(n^3)$ sodass $SAT\in\NTIME(f(n))$.

TODO: 

\begin{itemize}
 \item beschreibe Konstruktion von \ac{NTM} für \ac{SAT}
 \item Frage: Welche Laufzeitkomplexität hat diese \ac{NTM}?
 \item \ac{DTM}s?
\end{itemize}


\begin{Def}[name={[Polynom]}]
	Ein Polynom ist eine Funktion $p:\N\->\N$ mit $\exists k\in \N\ a_0,\dots,a_k\in\N$ und \mbox{$p(n)=\sum_i^k a_in^k$}
\end{Def}
\begin{Def}
 \begin{align*}
  \ac{P} &= \bigcup_{p\text{ Polynom}} \DTIME(p(n)) \\
  \ac{NP} &= \bigcup_{p\text{ Polynom}} \NTIME(p(n))
  \qedhere
 \end{align*}
\end{Def}



% \begin{Def}[name={[NP-Klasse]}]
% 	Die Klasse \ac{NP} besteht aus allen Sprachen, die von \ac{NTM} in polynomieller Zeit akzeptiert werden können.
% 	\[ \ac{NP} = \cup_{p\text{ Polynom}} \NTIME(p(n)) \]
% \end{Def}
% Analog für deterministische TM:
% \begin{Def}[name={[$\DTIME$ Klasse]}]
% 	Sei $f:\N\->\N$ Funktion\\
% 	$\DTIME(f(n)) =$ Klasse der Sprachen, die von \ac{DTM} in $T_M(w)\leq f(|w|)$ Schritten akzeptiert wird.
% 	\[ \ac{P} = \cup_{p\text{ Polynom}} DTIME(P(n)) \qedhere \]
% \end{Def}
Offenbar gilt $P\subseteq \ac{NP}$. Seit 1970 weiß man nicht, ob $P=\ac{NP}$ oder $P\neq \ac{NP}$ gilt.
\begin{description}
\item[Praktische Relevanz:] Es existieren wichtige Probleme, die offensichtlich in \ac{NP} liegen, aber die besten bekannten Algorithmen sind exponentiell.\\
	Beispiel: Traveling Salesman ($O(2^n)$), Erfüllbarkeit der Aussagenlogik.
\item[Struktur:] Viele der \ac{NP}-Probleme haben sich als gleichwertig erwiesen, in dem Sinn, dass eine \ac{P}-Lösung für alle anderen liefert.\\
	$\leadsto$ \ac{NP}-Vollständigkeit.
\end{description}

\begin{Def}[Polynomielle Reduktion]\label{def:PolyReduktion}\ \\
  Seien $U, V \subseteq \Sigma^*$ Sprachen.
  \emph{$U$ ist auf $V$ polynomiell reduzierbar (Notation: $U \preceq_p V$)}, falls eine totale, berechenbare Funktion
  $f:\Sigma^* \to \Sigma^*$ existiert, sodass
  \begin{itemize}
   \item $\forall w \in \Sigma^*:w \in U \iff f(w) \in V$
   \item $f$ wird von einer \ac{DTM} berechnet, deren Laufzeitkomplexität ein Polynom ist.
  \end{itemize}
  Wir nennen $f$ \emph{Reduktionsfunktion}.
\end{Def}

\datenote{02.02.2018}
Eine aussagenlogische Formel $F$ ist in \emph{konjunktiver Normalform} (CNF)\footnote{%
Verwechslungsgefahr: \ac{CNF} stand bisher immer für \acl{CNF}.
In diesem Kapitel werden wir diese aber nicht benötigen.
}, wenn $F$ eine Konjunktion von Disjunktionen von Literalen ist.
Wir verwenden \emph{CNF} als Notation für die Menge aller AL-Formeln in CNF.
Analog schreiben wir \emph{3CNF} für die Menge aller Formeln in CNF, bei denen jeder Konjunkt aus höchstens drei Disjunkten besteht.



\begin{Def}[name={[3SAT]}]
Das Problem \acsu{3SAT} ist wie folgt definiert.\footnote{
Typischerweise nennt man Sprachen, die im Kontext der Komplexitätstheorie definiert werden, \emph{Probleme}.
Es ist üblich, von einem konkreten Alphabet $\Sigma$ und einer konkreten Codierung der Objekte (hier: Formeln) zu abstrahieren und das Problem als (Gegeben, Frage)-Paar zu formulieren.
Es bleibt dem Leser überlassen, sich selbst geeignete Alphabete und Codierungen zu überlegen.
Für den Fall von aussagenlogische Formeln haben wir dies in {\color{red} TODO} noch einmal gemacht, werden aber in Zukunft darauf verzichten.}
\begin{center}
\framebox[\textwidth]{\parbox{.95\textwidth}{
\smallskip
\textit{Gegeben:} Eine aussagenlogische Formel $F\in$ \emph{3CNF}

\medskip

\textit{Frage:} Ist $F$ erfüllbar?
}}
\end{center}
	
\end{Def}
Alternativ könnten wir die Definition von \ac{3SAT} auch wie folgt aufschreiben.
$$\ac{3SAT} = \{F\in L(\mathcal{G}_\mathsf{AL})\mid F \text{ ist in 3CNF}\}$$

Offensichtlich gilt $\ac{3SAT} \preceq_p \ac{SAT}$.\footnote{
In der Vorlesung vom 02.02. wurde (fälschlicherweise) gesagt, die Identität sei eine geeignete Reduktionsfunktion.
Dies ist nicht korrekt, da z.B. 
$(A_1\lor A_2\lor A_3\lor A_4)\notin \ac{3SAT}$
(weil nicht in 3CNF), aber $(A_1\lor A_2\lor A_3\lor A_4)\in \ac{SAT}$.
} Wir zeigen als Nächstes auch die umgekehrte Richtung.

\begin{lemma}\label{lem:sat3sat}
	$\ac{SAT} \preceq_p \ac{3SAT}$
\end{lemma}


\begin{proof}
Unser Ziel ist es nun, eine Transformation anzugeben, die sich in polynomieller Zeit berechnen lässt und jede aussagenlogische Formel $F_\mathsf{AL}$ in eine 3CNF-Formel $F_\mathsf{3CNF}$ überführt, sodass
$F_\mathsf{AL}\in \ac{SAT} \<==> F_\mathsf{3CNF}\in \ac{3SAT}$
gilt.

Sei $F_\mathsf{AL}$ eine beliebige Formel aus $L(\mathcal{G}_\mathsf{AL})$.

\begin{enumerate}
 \item Erzeuge aus $F_\mathsf{AL}$ eine äquivalente Formel $F_\mathsf{NNF}$ in Negationsnormalform\footnote{Eine Formel ist in Negationsnormalform, wenn der Negationsoperator immer nur direkt vor einer Variable vorkommt.}.
 Wir können jede Formel in Negationsnormalform bringen, indem wir mit Hilfe der De Morganschen Regeln die Negationen "`nach innen"' ziehen.
 
 Beispiel: $\neg(\neg (A_1\lor \neg A_3)\lor A_2) \quad\rightsquigarrow\quad ((A_1\lor \neg A_3)\land \neg A_2)$
 
 Ideen zur Implementierung: Erstelle auf einem zusätzlichen Band eine Kopie der Formel.
 Lasse vor jedem nicht negierten Literal ein Feld Platz, um später ggf.\ ein Negationssymbol zu platzieren.
 Wende De Morgans Regel von außen nach innen an.
 Laufe für jede Anwendung einmal über die Formel.
 
 
 \item Erzeuge aus $F_\mathsf{NNF}$ eine Formel $F_{\alpha\gamma}$ mit Biimplikationszeichen "`$\<->$"' mit Hilfe der folgenden induktiv definierten Abbildungen $\alpha$ und $\gamma$.\footnote{%
 Die hier beschriebene Transformation ist auch als Tseytin-Transformation bekannt.}
 
 Idee: Die Abbildung $\gamma$ liefert für jede $\land$-Teilformel und jede $\lor$-Teilformel eine neue Hilfsvariable.
 Diese Hilfsvariable hat in der resultierenden Formel den Wahrheitswert, den die entsprechende Teilformel in der Eingabeformel hätte.
 Die Abbildung $\alpha$ konstruiert für jede Teilformel die entsprechenden Bedingungen für die Hilfsvariable.
 Erzeugt $\gamma$ keine Hilfsvariable, so erzeugt $\alpha$ die (nicht einschränkende) Bedingung~$1$.
 
 $$\gamma(F)=
 \begin{cases}
   0 & \text{ falls } F=0\\
   1 & \text{ falls } F=1\\
   A & \text{ falls } F=A\\
   \neg F_1 & \text{ falls } F=\neg F_1\\
   B_F & \text{ falls } F=F_1\land F_2\\
   B_F & \text{ falls } F=F_1\lor F_2
  \end{cases}$$
 
 
 
 $$\alpha(F)=
 \begin{cases}
   1 & \text{ falls } F=0\\
   1 & \text{ falls } F=1\\
   1 & \text{ falls } F=A\\
   1 & \text{ falls } F=\neg F_1\\
   \big(\gamma(F)\<-> \gamma(F_1) \land \gamma(F_2)\big)\land\alpha(F_1)\land\alpha(F_2) & \text{ falls } F=F_1\land F_2\\
   \big(\gamma(F)\<-> \gamma(F_1) \lor \gamma(F_2)\big)\land\alpha(F_1)\land\alpha(F_2) & \text{ falls } F=F_1\lor F_2
  \end{cases}$$
  
  Wir definieren das Resultat $F_{\alpha\gamma}:=\gamma(F_\mathsf{NNF})\land \alpha(F_\mathsf{NNF})$.
  
  Beispiel:
  \begin{align*}
   \alpha((A_1\lor \neg A_3)\land \neg A_2)) = & \;
  \big(B_{((A_1\lor \neg A_3)\land \neg A_2)} \leftrightarrow (B_{(A_1\lor \neg A_3)} \land \neg A_2)\big)\\
  & \land (B_{(A_1\lor \neg A_3)} \leftrightarrow (A_1\lor \neg A_3)) \land 1 \land 1\\
  & \land 1
  \end{align*}

  
  Ideen zur Implementierung:
  
  Wähle ein Bandalphabet, sodass das Zeichen $B$ enthalten ist.
  Verwende außerdem eine zusätzliche Art von Klammern (z.B. eckige Klammern), um den Subskriptanteil der B-Variablen vom restlichen Bandinhalt zu unterscheiden.
  Laufe für jede $\{\land,\lor\}$-Teilformel einmal über die Eingabe.
  Verwende ein zusätzliches Band zum Schreiben des Resultats.
  Verwende noch ein zusätzliches Band für die aktuell bearbeitete $\{\land,\lor\}$-Teilformel, da diese immer zweimal benötigt wird (Variablenname und $\alpha$).
  Bearbeite äußere Teilformeln vor inneren.
  Lösche Teile, die nicht mehr benötigt werden.
\item Ersetze die Formelteile mit Biimplikationszeichen in $F_{\alpha\gamma}$ wie folgt durch logisch äquivalente Formeln in 3CNF.
	\begin{itemize}
	\item $F_1\<-> (F_2\land F_3)
% 		= \big(F_1\land (F_2\land F_3)\big)\lor \big(\neg F_1\land \neg(F_2\land F_3)\big)
% 		= \big(F_1\lor \neg(F_2\land F_3)\big)\land \big(\neg F_1\lor (F_2\land F_3)\big)
		\quad\rightsquigarrow\quad \big(F_1\lor \neg F_2\lor \neg F_3\big)\land \big(\neg F_1\lor F_2\big)\land \big(\neg F_1\lor F_3\big)
		$
	\item $F_1\<-> (F_2\lor F_3)
% 		= \big(F_1\lor \neg(F_2\lor F_3)\big)\land \big(\neg F_1\lor (F_2\lor F_3)\big)
		\quad\rightsquigarrow\quad \big(F_1\lor \neg F_2\big)\land\big(F_1\lor \neg F_3\big)\land \big(\neg F_1\lor F_2\lor F_3\big)
$
	\end{itemize}
	
	Ideen zur Implementierung:
	
	Verwende ein zusätzliches Band zum Schreiben des Resultats.
	Verwende noch ein zusätzliches Band für die Operanden der Biimplikation, da diese immer mehrfach benötigt werden.
  
\item Ersetze alle aussagenlogischen Variablen der Form $B_F$ durch aussagenlogische Variablen der Form $A_i$.\footnote{%
Dieser Schritt ist nur nötig, damit das Resultat in dem von uns definierten Alphabet $\Sigma_{AL}$ dargestellt werden kann.
Alternativ hätten wir auch zu Beginn ein reichhaltigeres Alphabet wählen können.
}

	Ideen zur Implementierung:
	
    Finde zunächst den höchsten Index $i_{max}$ von $A_i$-Variablen (speichere aktuelles Maximum auf zusätzlichem Band).
    Verwende anschließend $i_{max}+1, i_{max}+2, \ldots$ für neue Variablen.
    Schreibe zunächst eine Übersetzungsvorschrift (z.B.\ $A_4:=B_{((A_1\lor \neg A_3)\land \neg A_2)}, A_5:=B_{(A_1\lor \neg A_3)}$) auf ein zusätzliches Band und ersetze erst dann.

\end{enumerate}

Sei $f:\Sigma_{AL}\rightarrow\Sigma_{AL}$ eine Funktion, die alle Formeln aus $L(\mathcal{G}_\mathsf{AL})$ entsprechend obiger Konstruktion abbildet und alle anderen Wörter unverändert lässt. Dann gilt:
\begin{itemize}
 \item $F_{AL}\in \ac{SAT} \<==> f(F_{AL})\in \ac{3SAT}$ (hier ohne Beweis)
 \item $f$ ist total und lässt sich in polynomieller Zeit berechnen (hier ohne Beweis).
 \qedhere
\end{itemize}
\end{proof}



\begin{lemma}\label{lem:A<B + BinP => AinP}
	Falls $A\preceq_p B$ und $B\in \ac{P}$ (bzw.\ $B\in \ac{NP}$), dann gilt auch $A\in \ac{P}$ (bzw.\ $A\in \ac{NP}$).
\end{lemma}
\begin{proof}
	$B\in \ac{P}$: Nach Annahme gibt es eine \ac{TM} $\M$, die $B$ in $p(n)$ Schritten akzeptiert.\\
	Es gibt außerdem eine \ac{TM} $\M_f$, welche die Reduktion $A\preceq_p B$ implementiert.
	Die Laufzeit von $\M_f$ sei durch das Polynom $q$ beschränkt.\\
	Betrachte $\M'$ = "`erst $\M_f$, dann $\M$ auf dem Ergebnis"'.
	$\M'$ akzeptiert $A$.\\
	Sei $w\in A$.
	$\M_f(w)$ liefert $f(w)$ in höchstens $q(|w|)$ Schritten mit $|f(w)|\leq q(|w|) + |w|$.\\
	$\M$ angesetzt auf $f(w)$ benötigt höchstens $p(|f(w)|)\leq p(q(|w|) + |w|)$ Schritte zum Akzeptieren.\\
	Insgesamt gilt also $A\in \DTIME(q(|w|) + |w|+p(q(|w|) + |w|)\subseteq \ac{P}$.
\end{proof}


% \draftnote{8.2.17}

\begin{Def}[name={[\ac{NP}-schwierig und \ac{NP}-vollständig]}]\
	\begin{itemize}
	\item Eine Sprache $U$ heißt \emph{\ac{NP}-schwierig}, falls $\forall L\in \ac{NP}$ gilt: $L\preceq_p U$.
	\item Eine Sprache $U$ heißt \emph{\ac{NP}-vollständig}, falls $U$ \ac{NP}-schwierig ist und $U\in \ac{NP}$ gilt. \qedhere
	\end{itemize}
\end{Def}

{\color{red}
TODO: Ausformulieren
\begin{itemize}
 \item \ac{NP}-schwierig, sehr starke Forderung dass an alle(!) \ac{NP}-Probleme reduzieren kann
 \item zunächst unklar ob es überhaupt ein \ac{NP}-schwieriges Problem gibt
 \item bedeutet: wenn ich das \ac{NP}-vollst. Problem gefunden habe dass ich effizient Lösen kann, kann ich alle \ac{NP}-Probleme effizient lösen (wie folgender Satz zeigt).
\end{itemize}
}
\begin{Satz}
	Wenn eine Sprache $A$ \ac{NP}-vollständig ist, dann gilt die folgende Äquivalenz.
	\[ A\in \ac{P} \<==> \ac{P} =\ac{NP} \qedhere \]
\end{Satz}
\begin{proof}\ \\
	"`\<=="' trivial.\\
	"`\==>"' Es gilt $A\in \ac{P} \subseteq \ac{NP}$. Da $A$ \ac{NP}-vollständig ist, gilt $\forall L\in \ac{NP}: L\preceq_p A$. Dann folgt mit \autoref{lem:A<B + BinP => AinP} auch $L\in \ac{P}$.
\end{proof}

\begin{lemma}[name={[$\preceq_p$ ist reflexiv und transitiv]}]
	$\preceq_p$ ist reflexiv und transitiv.
\end{lemma}
\begin{proof}
Übungsblatt~14, Aufgabe~1.
% 	Identität; ähnlich wie Beweis von \autoref{lem:A<B + BinP => AinP}.
\end{proof}

\begin{Bem}
    Aus der Transitivität folgt:
	Sobald ein \ac{NP}-schwieriges Problem $U$ bekannt ist, reicht es $U\preceq_p V$ zu zeigen, um zu beweisen, dass $V$ ebenfalls \ac{NP}-schwierig ist.
\end{Bem}
% Ein erstes \ac{NP}-vollständiges Problem.

\begin{Satz}[Cook]\label{satz:cook}
	\ac{SAT} ist \ac{NP}-vollständig.
\end{Satz}
Wir werden nur für \ac{SAT} die \ac{NP}-Schwierigkeit direkt beweisen und für alle anderen \ac{NP}-vollständigen Probleme die \ac{NP}-Schwierigkeit wie in obiger Bemerkung angedeutet mit Hilfe einer polynomiellen Reduktion zeigen.
Da der Beweis von \autoref{satz:cook} sehr umfangreich ist, wollen wir diesen etwas aufschieben und zunächst die \ac{NP}-Vollständigkeit weiterer Probleme zeigen.


\begin{Satz}[name={[3SAT ist \ac{NP}-vollständig]}]
	\ac{3SAT} ist \ac{NP}-vollständig.
\end{Satz}
\begin{proof}
 \
 \begin{itemize}
  \item $\ac{3SAT} \in \ac{NP}$
  
  Wir können dies auf zwei Arten zeigen. 
  Entweder wir zeigen direkt, dass es eine \ac{NTM} gibt, die \ac{3SAT} in polynomieller Zeit entscheidet, oder
  wir zeigen dies indirekt mit Hilfe einer polynomiellen Reduktion auf ein Problem in \ac{NP}.
  Wir wählen letzteres Vorgehen, da zum Beweis nur nochmal erwähnt werden muss, dass $\ac{SAT} \in \ac{NP}$ und (offensichtlich) $\ac{3SAT} \preceq_p \ac{SAT}$ gilt.
  
  \item \ac{3SAT} ist \ac{NP}-schwierig
  
  Folgt aus \autoref{lem:sat3sat}.\qedhere
 \end{itemize}
\end{proof}


Wir gehen davon aus, dass die Leser des Skripts mit Graphen vertraut sind, machen aber zum Fixieren von Notation und Terminologie die folgende Definition.
\begin{Def}
 Ein \emph{gerichteter Graph} ist ein Paar $\mathcal{G}=(V,E)$, bei dem
 \begin{itemize}
  \item $V$ eine Menge ist, deren Elemente wir \emph{Knoten} nennen und
  \item $E\subseteq V\times V$ eine Menge von geordneten Paaren über $V$ ist. 
  Wir nennen diese geordneten Paare \emph{Kanten}.
 \end{itemize}
 Ein \emph{ungerichteter Graph} ist ein gerichteter Graph, bei dem $E$ symmetrisch ist.\footnote{%
 Für die Zwecke dieser Vorlesung ist es komfortabel, den ungerichteten Graphen als Spezialfall des gerichteten Graphen zu definieren.
 Eine häufig verwendete Alternative ist, die Knotenmenge als Menge von zweielementigen Mengen zu definieren.}
\end{Def}



\begin{Def}[$\CLIQUE$]
    Das Problem $\CLIQUE$ ist wie folgt definiert.
    \begin{center}
    \framebox[\textwidth]{\parbox{.95\textwidth}{
    \smallskip
    \textit{Gegeben:} Ein ungerichteter Graph $\mathcal{G}=(V,E)$ und eine Zahl $k\in\N$.

    \medskip

    \textit{Frage:} Hat $\mathcal{G}$ eine $k$-Clique?
    
    Eine $k$-Clique ist eine $k$-elementige Menge von Knoten, die paarweise durch Kanten verbunden sind,
    d.h., eine Menge $C \subseteq V$, sodass $|C|=k$ und $\forall u, v\in C: u\neq v\rightarrow (u,v)\in E$.
    }}
    \end{center}
\end{Def}
\begin{Satz}[name={[$\CLIQUE$ ist \ac{NP}-vollständig]}]
	$\CLIQUE$ ist \ac{NP}-vollständig.
\end{Satz}
\begin{Bemerkung}
 Der folgende Beweis ist für ein Vorlesungsskript sehr knapp gehalten.
 Der Beweis enthält aber genau die Informationen, die wir in Übungsaufgaben und Klausur zum Erreichen der maximalen Punktzahl erwarten würde.
 
 Beweise der \ac{NP}-Vollständigkeit folgen typischerweise dem hier verwendeten Schema.
 Der schwierige (da Kreativität erfordernde) Teil ist dabei, eine geeignete Konstruktion für die Reduktionsfunktion zu finden.
 Für den folgenden Beweis wird die Idee der Konstruktion in \autoref{fig:3sat-clique} mit Hilfe eines Beispiels illustriert.
 
 In unseren Übungs- und Klausuraufgaben wird die Aufgabenstellung manchmal solch ein Beispiel enthalten.
 Damit soll ein Hinweis auf eine geeignete Konstruktion gegeben werden.
 Eine Besonderheit des folgenden Beweises ist, dass die Konstruktion aus zwei Schritten besteht (Erweiterung der Eingabeformel, Konstruktion des Graphen). Beide Schritte werden in \autoref{fig:3sat-clique} illustriert.
\end{Bemerkung}

\begin{proof}
    \
    \begin{itemize}
     \item Zeige $\CLIQUE\in \ac{NP}$.
     
     Verfahren: 
     Wähle nichtdeterministisch eine $k$-elementige Knotenmenge $C$.
     Prüfe, ob $C$ eine Clique ist.
     Dies ist in polynomieller Laufzeit möglich, da wir für jedes Knotenpaar höchstens einmal die Menge der Kanten durchlaufen müssen.
     
     \item Zeige, dass $\CLIQUE$ \ac{NP}-schwierig ist (mit Hilfe der Reduktion  $\ac{3SAT} \preceq_p \CLIQUE$).
     
     Ziel: Konstruiere für eine gegebene 3CNF-Formel $F$ einen Graphen $\mathcal{G}=(V,E)$, sodass $F$ genau dann erfüllbar ist, wenn $\mathcal{G}$ eine $k$-Clique hat.
     
     Unsere Konstruktion besteht aus zwei Schritten.
     Gegeben sei eine 3CNF-Formel $F$ mit $m$ Konjunkten.
     
     \begin{itemize}
      \item Schritt 1.
      
      Erweitere $F$, sodass jeder Konjunkt aus genau drei Disjunkten besteht.
      Wähle hierfür eine Äquivalenzumformung, die einfach nur existierende Disjunkte wiederholt.
      Die resultierende Formel $F'$ hat also die folgende Form.
      
      $F' = \bigwedge\limits_{i=1}^m (z_{i,1}\lor z_{i,2}\lor z_{i,3})$, wobei\ $z_{i,j}\in \{A_1,\dots,A_n\}\cup\{\neg A_1,\dots,\neg A_n\}$
      \item Schritt 2.
       Definiere zu einer Formel $F$ mit $m$ Konjunkten den Graphen $\mathcal{G} = (V,E)$ und $k$ wie folgt:
	\begin{align*}
		V &= \{ (i,j) \mid 1\leq i\leq m, j\in\{1,2,3\} \}\\
		E &= \{\big((i,j),(p,q)\big) \mid i\neq p, z_{i,j}\neq\neg z_{p,q}\}\\
		k &= m
	\end{align*}
     \end{itemize}

    Es gibt offensichtlich eine totale Reduktionsfunktion, welche diese Konstruktion in polynomieller Zeit berechnet.
    Nun gilt:
    %
    \begin{align*}
    F \text{ ist erfüllbar } \<==> \;\; & \text{Es gibt eine Folge $z_{1,j_1},\dots,z_{m,j_m}$, sodass $F$ unter der}\\
    & \text{Belegung, die jedem Folgenglied $1$ zuordnet, erfüllt ist.}\\
    \<==> \;\;   & \text{Es gibt eine Folge $z_{1,j_1},\dots,z_{m,j_m}$, sodass in jedem Konjunkt}\\
    & \text{ein $z_{i,j_i}$ vorkommt und $\forall i\neq p: z_{i,j_i}\neq \neg z_{p,j_p}$ gilt.}\\
    \<==> \;\;   & \text{$\mathcal{G}$ hat eine Menge von Knoten $\{(1,j_1),\dots,(m,j_m)\}$,}\\
    & \text{die paarweise durch Kanten verbunden sind.}\\
    \<==> \;\;   & \text{$\mathcal{G}$ hat eine $k$-Clique für $k=m$.}
    \end{align*}
    %
    Damit haben wir $\ac{3SAT} \preceq_p \CLIQUE$ gezeigt.
    \qedhere
    \end{itemize}
\end{proof}



 \begin{figure}[H]
 \framebox{
 \begin{minipage}{0.96\textwidth}
 Die Formel 
 $$ (X\lor\neg Y)\land (Y\lor \neg X)\land (X\lor Y) $$
 ist in 3CNF. Die folgende Formel ist äquivalent und jeder Konjunkt besteht aus drei Disjunkten.
 $$ \underbrace{(X\lor\neg Y\lor \neg Y)}_{1}\land \underbrace{(Y\lor \neg X\lor\neg X)}_{2}\land \underbrace{(X\lor X\lor Y)}_{3} $$
 Die Belegung $\beta$ definiert durch $\beta(X)=1, \beta(Y)=1$ ist eine erfüllende Belegung für diese Formel,
 da z.B. der erste Disjunkt im ersten Konjunkt, der erste Disjunkt im zweiten Konjunkt und der dritte Disjunkt im dritten Konjunkt auf 1 gesetzt sind.
 
 Im folgenden Graphen bilden die Knoten $(1,1)$, $(2,1)$ und $(3,3)$ eine $3$-Clique.
 
 \centering
\begin{tikzpicture}[
% node distance=1mm
]
\node (11) at (-2,-1.5) {$(1,1)$};
\node (12) at (0,-1.5) {$(1,2)$};
\node (13) at (2,-1.5) {$(1,3)$};

\node (21) at (-2,3) {$(2,1)$};
\node (22) at (-3,2) {$(2,2)$};
\node (23) at (-4,1) {$(2,3)$};

\node (31) at (2,3) {$(3,1)$};
\node (32) at (3,2) {$(3,2)$};
\node (33) at (4,1) {$(3,3)$};

\node (11v) [node distance=1mm, below =of 11] {$X$};
\node (12v) [node distance=1mm, below =of 12] {$\neg Y$};
\node (13v) [node distance=1mm, below =of 13] {$\neg Y$};

\node (21v) [node distance=1mm, above left =of 21] {$Y$};
\node (22v) [node distance=1mm, above left =of 22] {$\neg X$};
\node (23v) [node distance=1mm, above left =of 23] {$\neg X$};

\node (31v) [node distance=1mm, above right =of 31] {$X$};
\node (32v) [node distance=1mm, above right =of 32] {$X$};
\node (33v) [node distance=1mm, above right =of 33] {$Y$};

\draw[-,very thick] (11) to (21);
\draw[-] (11) to (31);
\draw[-] (11) to (32);
\draw[-,very thick] (11) to (33);

\draw[-] (12) to (22);
\draw[-] (12) to (23);
\draw[-] (12) to (31);
\draw[-] (12) to (32);

\draw[-] (13) to (22);
\draw[-] (13) to (23);
\draw[-] (13) to (31);
\draw[-] (13) to (32);

\draw[-] (21) to (31);
\draw[-] (21) to (32);
\draw[-,very thick] (21) to (33);

\draw[-] (22) to (33);
\draw[-] (23) to (33);
\end{tikzpicture}
\end{minipage}
}
	\caption{Beispiel zu $\ac{3SAT} \preceq_p \CLIQUE$}
	\label{fig:3sat-clique}
\end{figure}






% \begin{Bsp*}
% 	\begin{align*}
% 	F &= (\underbrace{x\lor y\lor \overline{y}}_1) \land (\underbrace{z\lor \overline{y} \lor \overline x}_2)\\
% 	\mathcal{G} &: \tikz[baseline=(11.base),label distance=-.5em]\graph[math nodes, chain shift={(0,-1)}, group shift={(1,0)}]{
% 		{x[label={[name=11](1,1)}], y[label={(1,2)}], "\overline y"[label={(1,3)}]}
% 		--[complete bipartite] 
% 		{z[label={below:(2,1)}], 22/\overline y[label={below:(2,2)}], "\overline x"[label={below:(2,3)}]}
% 	};
% 	\end{align*}\rlnote{Grafik überprüfen}
% \end{Bsp*}

An dieser Stelle wollen wir nun den Beweis von \autoref{satz:cook} nachholen.
\datenote{07.02.2018}
Wir benötigen dafür zunächst das folgende Lemma.
\begin{lemma}
	Für jedes $k\in\N$ existiert eine Formel $G$, sodass $G(x_1,\dots,x_k)=1$ gdw. $\exists j: x_j = 1$ und $\forall i \neq j: x_i = 0$. Es gilt $|G| \in O(k^2)$.
\end{lemma}
\begin{proof}
	\[ G(x_1,\dots,x_k) = \bigvee_{i=1}^k x_i\land \bigwedge_{i\neq j}\neg (x_i\land x_j) \]
	$\M=(Q,\Sigma,\Gamma,\delta,q_0,\blank,F)$ akzeptiert $L$ in $\NTIME(p),\ p$ Polynom.
\end{proof}

\begin{proof}[von \autoref{satz:cook}]\
	\begin{enumerate}
	\item $\ac{SAT} \in \ac{NP}$\\
		Rate nichtdeterministisch eine Belegung $\beta$.\\
		Werte anschließend $F[\beta]$ in polynomieller Zeit aus.
% 		$\curvearrowright$ in $\NTIME(n)$, polynomiell
	\item \ac{SAT} ist \ac{NP}-schwierig.\\
		Zeige: $\forall L\in \ac{NP}: L \preceq_p \ac{SAT}$\\
		Sei $L\in \ac{NP}$, d.h., es gibt ein Polynom $p$ und eine \ac{NTM} $\M$ mit $L=L(\M)$ mit Zeitkomplexität $p(n)$ für $n = |w|$.
		
		Sei $w = x_1\dots x_n\in\Sigma^*$ eine beliebige Eingabe für $\M$ der Länge~$n$.\\
		Ziel: Definiere $F$, sodass $F$ erfüllbar $\<==> \M$ akzeptiert $w$.
		
		Seien $Q$ die Zustandsmenge von $\M$ mit $\{q_1,\dots,q_k\}=Q$ und $\Gamma$ das Bandalphabet von $\M$ mit $\{a_1,\dots,a_l\} = \Gamma$.\\
		Seien $t\in\{0,1,\dots,p(n)\}$, $i\in\{-p(n),\dots,-1,0,1,\dots,p(n)\}$, $q \in Q$ und $a\in\Gamma$. \\
		Definiere damit folgende aussagenlogische Variablen zur Verwendung in $F$.
		\begin{itemize}
		\item $\mathrm{state}(t,q) = 1$ gdw.\ $\M$ nach $t$ Schritten im Zustand $q$ ist
		\item $\mathrm{pos}(t,i) = 1$ gdw.\ der Kopf von $\M$ nach $t$ Schritten auf Position $i$ steht.
		\item $\mathrm{tape}(t,i,a) = 1$ gdw.\ nach $t$ Schritten an Position $i$ ein $a$ steht.
		\end{itemize}
	\end{enumerate}

	\medskip

	Wir setzen $F = R \land A\land T_1 \land T_2 \land E$, wobei die Teilformeln folgendermaßen definiert sind.
	\begin{enumerate}
	\item Randbedingungen
		\begin{align*}
			R\ =&\phantom{\land}\, \bigwedge_t G(\state(t,q_1),\dots,\state(t,q_k))\\
			& \land \bigwedge_t G(\pos(t,-p(n)),\dots,\pos(t,0),\dots,\pos(t,p(n)))\\
			& \land \bigwedge_{t,i} G(\tape(t,i,a_1),\dots,\tape(t,i,a_l))
		\end{align*}
	\item Anfangskonfiguration
		\begin{align*}
			A\ =&\phantom{\land}\; \state(0,q_1)\land \pos(0,1)\\
			&\land\tape(0,1,x_1)\land\dots\land\tape(0,n,x_n)\\
			&\land\bigwedge_{i< 1 \lor i > n} \tape(0,i,\blank)
		\end{align*}
	\item Transitionsschritte
	\begin{align*}
		T_1\ =& \bigwedge_{\substack{t < p(n),\\i,q}} \state(t,q)\land \pos(t,i) \land \tape(t,i,a)\\
		&\qquad \-> \bigvee_{1 \leq m \leq |\delta(q,a)|} \state(t+1,q_m')\land \pos(t+1,i+d_m) \land \tape(t+1,i,a_m')\\
		&\qquad \text{für jede Transition } (q_m',a_m',d_m) \in \delta(q,a) \text{ mit } d_m\in\{-1,0,1\}\\
		T_2\ =& \bigwedge_{\substack{t < p(n),\\i,q}} \neg \pos(t,i)\land \tape(t,i,a) \-> \tape(t+1,i,a)
	\end{align*}
	\item Endkonfiguration%
% 	\footnote{Wir gehen hier davon aus, dass $\M$ erst im allerletzten Schritt $p(n)$ anhält.}
		\[ E = \bigvee_{q\in F} \state(p(n),q) \]
		$|F|$ ist polynomiell beschränkt in $|\M|+|w|$, also gilt $L\preceq_p \ac{SAT}$.%
		\footnote{$|\M|$ dürfen wir als zu $L$ gehörende Konstante betrachten.}\\
		Es ist klar, dass gilt: $F$ erfüllbar $\<==> \M$ akzeptiert $w$.\\
		Damit haben wir "`$\ac{SAT}$ ist \ac{NP}-vollständig"' gezeigt.
		\qedhere
	\end{enumerate}
\end{proof}

% \subsection{Weitere \ac{NP}-vollständige Probleme}










\newpage

\section{Einordnung von Sprachen in Chomsky-Hierarchie und Abschlusseigenschaften}

Wir haben bereits gesehen, dass jede Laufzeitschranke auch eine Beschränkung der Platzkomplexität impliziert,
wir werden nun sehen dass zumindest für haltende DTMs auch die umgekehrte Richtung gilt.
\begin{lemma}\label{lem:endlichKonfigurationen}
 Seit $\M$ eine \ac{TM} mit Platzkomplexität $s(n)$.
 Dann durchläuft jede Berechnung höchstens $s(n)\cdot |Q| \cdot |\Gamma|^{s(n)}$
 verschiedene Konfigurationen.
\end{lemma}
\begin{proof}
 Es gibt 
 \begin{itemize}
  \item höchstens $s(n)$ mögliche Positionen an denen sich der Kopf befinden kann,
  \item höchstens $|Q|$ mögliche Zustände und
  \item jede Zelle des besuchten Bandes (davon gibt es höchstens $s(n)$ Stück) kann mit höchstens $|\Gamma|$ verschiedenen Zeichen beschriftet sein. \qedhere
 \end{itemize}
\end{proof}

\begin{Bemerkung}
 Für jede DTM mit Platzkomplexität $s(n)$ hält also jede Berechnung entweder
 \begin{itemize}
  \item nie oder
  \item nach höchstens $s(n)\cdot |Q| \cdot |\Gamma|^{s(n)}$ Schritten.
 \end{itemize}
Grund: \autoref{lem:endlichKonfigurationen} und sobald eine Konfiguration zum zweiten mal erreicht wurde ist die DTM in einer ''Endlosschleife``.
\end{Bemerkung}


\begin{Satz}
 Jede Sprache $L\in\NSPACE(n)$ ist entscheidbar.
\end{Satz}
\begin{proof}
 Wegen \autoref{lem:endlichKonfigurationen} genügt es jede Berechnung bis zu 
 $s(n)\cdot |Q| \cdot |\Gamma|^{s(n)}$
 Schritten zu simulieren um herauszufinden ob ein Wort der Länge $n$ akzeptiert wird.
\end{proof}


\begin{Satz}
 Jede Sprache $L\in\ch{1}$ ist entscheidbar.
\end{Satz}

\begin{proof}
 Sei $G=(\Sigma,N,P,S)$ Typ-1 Grammatik (kontxtsensitive Grammatik) für $L$, $w\in\Sigma^*$ und $n$ die Länge von $w$.
 Da alle Regeln expansiv (d.h., $\alpha\->\beta\in P \==> |\alpha|\leq |\beta|$) sind, 
 müssen wir nicht alle (unendlich viele!) Ableitungen betrachten.
 Es genügt wenn wir Ableitungen
 $$S\vdash\alpha_1\vdash \ldots \vdash\alpha_m,$$
 betrachten bei denen alle Satzformen $\alpha_j$ Länge $\leq n$ haben und paarweise verschieden sind.
\end{proof}








\begin{Satz}\label{satz:6.3}
	$\ch{1}=\NSPACE(n)$
\end{Satz}
\begin{proof}\
\begin{itemize}
	\item["`\=>"'\,:] Sei $G=(\Sigma,N,P,S)$ Typ-1 Grammatik für $L$.\\
		Konstruiere \ac{NTM} $M$ mit $L=L(M),\ \Gamma = \Sigma\cup N\cup\{\blank\}$
		\begin{enumerate}
		\item $M$ rät nicht deterministisch eine Position auf
                  dem Band und eine Produktion $\alpha\-> \beta$. Falls $\beta$ gefunden wird, ersetze durch $\alpha$, weiter bei 1.
		\item Falls Bandinhalt $=S$ \quad stop, akzeptiert.
		\end{enumerate}
		Dieses Verfahren terminiert.
	\item["`\<="'\,:] %
	Gegeben: \ac{NTM} $\M$ 
	Gesucht: Typ-1 Grammatik $\mathcal{G}$ mit $L(\mathcal{G})=L(M)$\\
	Wir wollen den Beweis hier nicht formal ausformulieren und beschreiben nur die zugrundliegenden Ideen.
	\begin{itemize}
	\item Idee 1:
	Ahme Berechnungsschritte der \ac{TM} mit Ableitungsschritten der Grammatik nach.
	Die Manipulierten Satzformen repräsentieren dabei Konfigurationen der TM.
	Wir wählen als (vorläufige) Variablenmenge $V'=\Gamma\cup(Q\x\Gamma)$.
	Eine Konfiguration $uqav$ mit $u,v\in\Gamma^*,a\in\Gamma$ wird durch die Satzform $u(q,a)v$ repräsentiert.
	Die Regeln sind wie folgt definiert.
	\begin{align*}
	 P' = \quad &\; \{ (q,a) \-> (q',a') \mid (q',a',N)\in \delta(q,a)\}\\
	 \cup &\; \{ (q,a)b \-> a'(q',b) \mid b\in\Gamma, (q',a',R)\in \delta(q,a) \}\\
	 \cup &\; \{ (q,a) \-> (q',a') \mid (q',a',L)\in \delta(q,a)\}
	\end{align*}
    Somit gilt, dass die \ac{TM} eine Konfiguration in eine andere überführen kann $uqav \vdash^{*} u'q'a'v'$
    genau dann wenn wir mit Regeln aus $P'$ die Ableitung $u(q,a)v \vdash^{*} u'(q',a')v'$ machen können.

	
	\item Idee 2:
	Die erste Idee hat noch das folgende Problem und muss deshalb ergänzt werden:
	Während eine \ac{TM} mit der Eingabe startet und diese in eine ''akzeptiert``/''akzeptiert nicht`` Antwort transformiert,
	arbeitet eine Grammatik umgekehrt. 
	Sie startet mit dem Startsymbol und am Ende erhalten wir das resultierende Wort.
	
	Wir Unterteilen die Satzformen der Grammatik in zwei Spuren, eine obere Spur und eine untere Spur.
	Die untere Spur enthält das Eingabewort, die untere Spur simuliert das Band der Turingmaschine.
	Formal erreichen wir dies in dem wir als Variablenmenge das Karthesische Produkt aus vorläufiger Variablenmenge und Alphabet nehmen:
	$N = \{S\}\dotcup N' \x\Sigma$
	
		\begin{align*}
		a_1\cdots a_n &\-->
			\pmqty{a_1\\a_1} \pmqty{a_2\\a_2} \pmqty{(q,a)\\a_3} \pmqty{a_4\\a_4} \pmqty{a_n\\a_n}
			&&\begin{matrix}\text{Spur 1}\\\text{Spur 2}\end{matrix}\\
	\end{align*}
	
	Eine Ableitung besteht dann aus drei Phasen.
	\begin{itemize}
	\item Phase 1: 
	Wir wählen nichtdeterministisch das Wort, dass wir erzeugen wollen (untere Spur) und bringen das Band der \ac{TM} (obere Spur) in die entsprechende Startkonfiguration.
	\item Phase 2:
	Wir simulieren auf der oberen Spur die Berechnungen der \ac{TM} bis eine Haltekonfiguration erreicht ist.
	\item Phase 3:
	Wenn die \ac{TM} in einem akzeptierenden Zustand ist ersetzen wir alle ''Zweispurzeichen`` durch das ensprechende Zeichen der unteren Spur und erhalten das Eingabewort.
	\end{itemize}
	
	
	
	\end{itemize}
	\begin{align*}
		\text{mit } P &= \\
		S &\-> \pmqty{(q_0,a)\\a} &&\forall a\in\Sigma\\
		S &\-> S\pmqty{a\\a} &&\forall a\in\Sigma\\
		\pmqty{\alpha\\a}
			&\-> \pmqty{\beta\\a}
			&&\begin{aligned}
				\forall \alpha\->\beta &\in P'\\
				\alpha,\beta &\in\triangle
			\end{aligned}\\
		\pmqty{\alpha_1\\a_1}\pmqty{\alpha_2\\a_2}
			&\-> \pmqty{\beta_1\\a_1}\pmqty{\beta_2\\a_2}
			&&\begin{aligned}
				\forall \alpha_1\alpha_2\->\beta_1\beta_2 &\in P'\\
				\alpha_i,\beta_i &\in\triangle
			\end{aligned}\\
		\pmqty{x\\a} &\-> a
			&&\begin{aligned}
				x&\in\Gamma\\
				a&\in\Sigma
			\end{aligned}\\
		\pmqty{(q',x)\\a} &\-> a
			&&\begin{aligned}
				x&\in\Gamma, q'\in F, \delta (q',x)=\emptyset\\
				a&\in\Sigma
			\end{aligned}
	\end{align*}
	\begin{align*}
		S &\xRightarrow{*} \pmqty{(q_0,a_1)\\a_1}\pmqty{a_2\\a_2}\dots\pmqty{a_n\\a_n}\\
		&\phantom{{}\xRightarrow{*}{}}\ \acs*{TM}\ \,\dots\\
		&\xRightarrow{*} \pmqty{x_1\\a_1}\dots\pmqty{(q',x_i)\\a_i}\dots\pmqty{x_n\\a_n}\\
		&\xRightarrow{*} a_1\dots a_i\dots a_n
	\end{align*}
	Damit gesehen $L(\mathcal{G})\subseteq L(M)$\\
	Rückrichtung: selbst \qedhere
	\end{itemize}
\end{proof}

\draftnote{09.02.2018}
\begin{Satz}
 Die Menge der entscheidbaren Sprachen ist verschieden von \ch{1}
\end{Satz}
\begin{proof}
 Wir konstruieren zunächst analog zu Abschnitt~\ref{subsec:codeTuring} eine Codierung von Grammatiken durch Wörter $w\in\{0,1\}^*$.
 Anschließend definieren wir $\mathcal{G}_w$ als die Grammatik die durch Wort $w$ codiert wird und wählen die leere Grammatik
 $(\{S\}, \{0,1\}, \{\}, S)$
 für den Fall, dass $w$ nicht Code einer Grammatik ist.
 
 Wir betrachten nun eine Matrix in deren Spalten alle Wörter $w_1,w_2,\ldots$
 aufgelistet und in deren Zeilen alle Grammatiken $\mathcal{G}_{w_1},\mathcal{G}_{w_2},\ldots$ aufgelistet sind.
 Ein Matrixeintrag $(\mathcal{G}_{w_i}, w_j)$ enthält ein Y wenn falls $w_j\in L(\mathcal{G}_{w_i})$ und ein N sonst.
 
 Da das Wortproblem für \ch{1} Sprachen entscheidbar ist, ist insbesondere der Test ''$w_k\in L(\mathcal{G}_{w_i})$``
 für alle Diagonaleinträge berechenbar und somit auch die Sprache $L_\mathsf{evil}= \{w \in\{0,1\}^* \mid w\notin L(\mathcal{G}_w)\}$ entscheidbar.
 
 Angenommen jede Entscheidbare Sprache sei \ch{1}, dann gibt es auch ein $w_k$ sodass $L(\mathcal{G}_{w_k})=L_\mathsf{evil}$.
 Nun gilt aber $w_k\in L_\mathsf{evil} \<==> w_k\notin L_\mathsf{evil}$. Widerspruch!
\end{proof}

 \begin{figure}[H]\centering

\begin{tikzpicture}[scale=0.7]

\draw[fill=lightgray!20, draw=lightgray!20] (-1.9,-3.5) rectangle (7.7,-4.5);

\node at (0,1) {$w_0$};
\node at (1,1) {$\dots$};
\node at (2,1) {$w_i$};
\node at (3,1) {$\dots$};
\node at (4,1) {$w_k$};
\node at (5,1) {$\dots$};
\node at (6,1) {$w_j$};
\node at (7,1) {$\dots$};

\node at (-1.2,0) {$\mathcal{G}_{w_0}$};
\node at (-1.2,-1) {$\vdots$};
\node at (-1.2,-2) {$\mathcal{G}_{w_i}$};
\node at (-1.2,-3) {$\vdots$};
\node at (-1.2,-4) {$\mathcal{G}_{w_k}$};
\node at (-1.2,-5) {$\vdots$};
\node at (-1.2,-6) {$\mathcal{G}_{w_j}$};
\node at (-1.2,-7) {$\vdots$};

\draw (-1.5, 0.5) to (7.5,0.5);
\draw (-0.5, 1.5) to (-0.5,-7.5);

\node[circle, draw=lightgray!50, fill=lightgray!50, inner sep=0] (00) at (0,0) {Y};
\node[lightgray] at (1,0) {$\ldots$};
\node[lightgray] at (2,0) {Y};
\node[lightgray] at (3,0) {$\ldots$};
\node[lightgray] at (4,0) {Y};
\node[lightgray] at (5,0) {$\ldots$};
\node[lightgray] at (6,0) {N};
\node[lightgray] at (7,0) {$\ldots$};

\node[lightgray] at (0,-2) {N};
\node[lightgray] at (1,-2) {$\ldots$};
\node[circle, draw=lightgray!50, fill=lightgray!50, inner sep=0] (ii) at (2,-2) {N};
\node[lightgray] at (3,-2) {$\ldots$};
\node[lightgray] at (4,-2) {Y};
\node[lightgray] at (5,-2) {$\ldots$};
\node[lightgray] at (6,-2) {Y};
\node[lightgray] at (7,-2) {$\ldots$};

\node (k0) at (0,-4) {N};
\node[lightgray] at (1,-4) {$\ldots$};
\node (ki) at (2,-4) {Y};
\node[lightgray] at (3,-4) {$\ldots$};
\node[circle, draw=lightgray!50, fill=lightgray!50, inner sep=1] (kk) at (4,-4) {\textbf{?}};
\node[lightgray] at (5,-4) {$\ldots$};
\node (kj) at (6,-4) {Y};
\node[lightgray] at (7,-4) {$\ldots$};

\node[lightgray] at (0,-6) {Y};
\node[lightgray] at (1,-6) {$\ldots$};
\node[lightgray] at (2,-6) {Y};
\node[lightgray] at (3,-6) {$\ldots$};
\node[lightgray] at (4,-6) {N};
\node[lightgray] at (5,-6) {$\ldots$};
\node[circle, draw=lightgray!50, fill=lightgray!50, inner sep=0] (jj) at (6,-6) {N};
\node[lightgray] at (7,-6) {$\ldots$};

\draw[->] (00) to (k0);
\draw[->] (ii) to (ki);
\draw[->] (jj) to (kj);

\end{tikzpicture}
	\caption{Illustration des Diagonalarguments beim Beweis dass nicht jede entscheidbare Sprache \ch{1} ist}
\end{figure}






\begin{Bemerkung}\
	\newcommand{\underarrowset}[2]{%
		\underset{%
			\mathclap{%
				\overset{\displaystyle\uparrow}{\mathclap{#1}}%
			}%
		}{#2}%
	}
	\begin{enumerate}
	\item Für "`$s(n)\leq n$"' betrachte 2-Band \ac{TM}, bei denen die Eingabe read-only ist und nur das zweite Arbeitsband der Platzschranke unterliegt (so ist $s(n)$ sublinear möglich).
	\item Jede Platzbeschränkung impliziert Laufzeitschranke.\\
	Angenommen Platzschranke $s(n)$\\
	$\curvearrowright$ \ac{TM} hat nur endlich viele Konfigurationen
	\[ N := \underarrowset{%
			\parbox{\widthof{\scriptsize Eingabeband}}{\raggedright\scriptsize Kopfpos. im Eingabeband}\hspace{1cm}
		}{n\vphantom{|}}
		|Q| \quad\cdot\quad
		\underarrowset{\parbox{2.2cm}{\scriptsize\centering mögliche Inhalte des Arbeitsbands}}{|\Gamma|}^{s(n)}
		\ \cdot\
		\underarrowset{\hspace{1.7cm}\parbox{2cm}{\scriptsize Kopfpos. auf\\ Arbeitsband}}{s(n)}
		\in 2^{O(\log n + s(n))}
	\]
	\item \ac{DTM} mit Platzschranke\,: $M$ entscheidet,\\
	falls sie akzeptiert, dann in weniger als $N$ Schritten,\\
	falls nach $N$ Schritten keine Terminierung erfolgt\\
	\quad$\curvearrowright$ Endlosschleife -- Abbruch
	\item \ac{NTM}\,: nutze den \ac{ND} optimistisch aus\,:\\
	falls eine akzeptierende Berechnung existiert, dann muss es eine Berechnung ohne wiederholte Konfiguration geben.
	\end{enumerate}
\end{Bemerkung}
\begin{Satz}[name={[$L\in\DTAPE(n),\ L\in\NTAPE(n)$]}]\label{satz:6.2}\
	\begin{itemize}
	\item $L\in\DTAPE(n) \curvearrowright\ \exists$ \ac{DTM}, die $L$ in Zeit $2^{O(n)}$ entscheidet.
	\item $L\in\NTAPE(n)$ analog.
	\end{itemize}
\end{Satz}\vspace{-2em}
\begin{proof}
	siehe oben.
\end{proof}
\begin{Bemerkung}
	Die Klasse $\NTAPE (n)$ heißt auch \ac{LBA}.
\end{Bemerkung}
%


\begin{Satz}
	Die Typ-1 Sprachen sind abgeschlossen unter {\thinmuskip=6mu$\cup,\cap,\cdot,{}^*$} und Komplement.
\end{Satz}
\begin{proof}
	Zu $\cup$ und $\cap$ betrachte \ac{NTM}.\\
	Für $\cdot$ und $^*$ konstruiere Grammatik.\\
	ad Komplement "`2. \acsu{LBA}-Problem\footnote{\acs*{LBA} = \acl*{LBA} -- 1964 Kuroda}"' bis 1987, dann gelöst durch Immerman und Szelepcsényi.
\end{proof}
\begin{Bemerkung}
  1. \ac{LBA}-Problem (1964): Ist $\mathrm{NTAPE}(n) = \mathrm{DTAPE}(n)$? Bisher ungelöst.
\end{Bemerkung}
\begin{Satz}
	Das Wortproblem für Typ-1 Sprachen ist entscheidbar.
\end{Satz}
\begin{proof}
	\begin{align*}
		L\in\mathcal{L}_1 &\curvearrowleftright L\in\mathrm{NTAPE}(n)\\
		&\curvearrowright \text{nach \autoref{satz:6.2}: $L$ entscheidbar}
	\end{align*}
	Nach \autoref{satz:6.1} sogar mit \ac{DTM}.
\end{proof}
Die Rückrichtung "`L entscheidbar. $\xcancel{\curvearrowright}\ L$ ist Typ-1 Sprache"' gilt nicht!

\subsection{Typ-0 Sprachen}

\begin{Satz}\label{satz:6.6}
	$\mathcal{L}_0 = \ac{NTM}$
\end{Satz}
\begin{proof}
	\begin{itemize}
	\item["'\=>"'] Konstruktion einer \ac{NTM} $M$ wie in \autoref{satz:6.3}, aber ohne Platzbeschränkung.
	\item["'\<="'] Konstruktion analog zu \autoref{satz:6.3} + Startsymbol $S'$
	\begin{align*}
		S' &\-> \pmqty{\blank\\\Eps} S' \pmqty{\blank\\\Eps} &&\text{Schaffe Platz für Berechnung von }M\\
		S' &\-> S\\
	\shortintertext{Erweitere $N$}
		&= \{S',S\}\cup\triangle\x(\Sigma\cup\{\Eps\})\\
	\shortintertext{Neue Löschregeln:}
		\pmqty{x\\ \Eps } &\-> \Eps &&\forall x\in\Gamma\\
		\rotatebox{90}{$\Rsh$}\ &\mathrlap{\text{die einzigen
                                          Regeln, die Typ-1 Bedingung verletzen.}} \tag*{\qedhere}
	\end{align*}
	\end{itemize}
\end{proof}

\begin{Satz}[name={[Abgeschlossenheit von Typ-0 Sprachen]}]\label{satz:Typ-0-abgeschl}
	Die Typ-0 Sprachen sind unter $\thinmuskip=6mu\cup,\cap,\cdot,{}^*$ abgeschlossen.
\end{Satz}
\begin{proof}
	Konstruiere \ac{NTM} für $\thinmuskip=6mu\cup,\cap$ ; Typ-0-Grammatiken für $\cdot$ und $^*$.
\end{proof}

\begin{Bem}
	Typ-0 Sprachen sind \emph{nicht} unter Komplement abgeschlossen!
\end{Bem}


\begin{Korollar}
	$\mathcal{L}_0 \supsetneqq \mathcal{L}_1$
\end{Korollar}
\begin{proof}
	$K$ ist unentscheidbar (also $\notin \mathcal{L}_1$), aber semi-entscheidbar (also $\in \mathcal{L}_0$).
\end{proof}
